{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\scago\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchaudio\\backend\\utils.py:74: UserWarning: No audio backend is available.\n",
      "  warnings.warn(\"No audio backend is available.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from utils.ipynb\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import mne\n",
    "import torch\n",
    "import pickle\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "import import_ipynb\n",
    "from utils import load_eeg_data\n",
    "from utils import load_eye_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_dict = {0:'Disgust', 1:'Fear', 2:'Sad', 3:'Neutral', 4:'Happy'}\n",
    "def load_eeg_data(eeg_dir, file_name, print_=True):\n",
    "    eeg_data_pickle = np.load( os.path.join(eeg_dir, file_name) )\n",
    "    data = pickle.loads(eeg_data_pickle['data'])\n",
    "    label = pickle.loads(eeg_data_pickle['label'])\n",
    "    label_dict = {0:'Disgust', 1:'Fear', 2:'Sad', 3:'Neutral', 4:'Happy'}\n",
    "    if(print_ == True):\n",
    "        for i in range(45):\n",
    "            print(f\"\\tSession {i//15+1} - Clip #{i%15+1} ----> {label_dict[label[i][0]]}\")\n",
    "    return data, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eye_movement_features = './dataset/Eye_movement_features'\n",
    "eeg_features = './dataset/EEG_DE_features'\n",
    "\n",
    "eeg_dir = eeg_features\n",
    "#eye_dir = eye_movement_features\n",
    "file_list = os.listdir(eeg_dir)\n",
    "file_list.sort()\n",
    "\n",
    "res_dir = './res/cv3/'\n",
    "if not os.path.exists(res_dir):\n",
    "    os.makedirs(res_dir)\n",
    "cv = 1\n",
    "\n",
    "# subjectID_sessionID.npz\n",
    "for f_id in file_list:\n",
    "    data, labels = load_eeg_data(eeg_dir, f_id, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1_1_20180804.cnt\n",
      "<Info | 9 non-empty values\n",
      " bads: []\n",
      " ch_names: FP1, FPZ, FP2, AF3, AF4, F7, F5, F3, F1, FZ, F2, F4, F6, F8, ...\n",
      " chs: 66 EEG\n",
      " custom_ref_applied: False\n",
      " dig: 69 items (3 Cardinal, 66 EEG)\n",
      " highpass: 0.0 Hz\n",
      " lowpass: 500.0 Hz\n",
      " meas_date: 2018-04-08 17:35:05 UTC\n",
      " nchan: 66\n",
      " projs: []\n",
      " sfreq: 1000.0 Hz\n",
      " subject_info: 5 items (dict)\n",
      ">\n",
      "1000.0\n",
      "['FP1', 'FPZ', 'FP2', 'AF3', 'AF4', 'F7', 'F5', 'F3', 'F1', 'FZ', 'F2', 'F4', 'F6', 'F8', 'FT7', 'FC5', 'FC3', 'FC1', 'FCZ', 'FC2', 'FC4', 'FC6', 'FT8', 'T7', 'C5', 'C3', 'C1', 'CZ', 'C2', 'C4', 'C6', 'T8', 'M1', 'TP7', 'CP5', 'CP3', 'CP1', 'CPZ', 'CP2', 'CP4', 'CP6', 'TP8', 'M2', 'P7', 'P5', 'P3', 'P1', 'PZ', 'P2', 'P4', 'P6', 'P8', 'PO7', 'PO5', 'PO3', 'POZ', 'PO4', 'PO6', 'PO8', 'CB1', 'O1', 'OZ', 'O2', 'CB2', 'VEO', 'HEO']\n"
     ]
    }
   ],
   "source": [
    "eeg_raw = './dataset/EEG_raw'\n",
    "# eye_raw = './dataset/Eye_raw'\n",
    "\n",
    "eeg_dir = eeg_raw\n",
    "# eye_dir = eye_raw\n",
    "file_list = os.listdir(eeg_dir)\n",
    "file_list.sort()\n",
    "\n",
    "res_dir = './res/cv3/'\n",
    "if not os.path.exists(res_dir):\n",
    "    os.makedirs(res_dir)\n",
    "\n",
    "\n",
    "# EEG RAW DATA\n",
    "for f_id in file_list:\n",
    "    print(f_id)\n",
    "    eeg_raw = mne.io.read_raw_cnt(f'./dataset/EEG_raw/{f_id}')\n",
    "    # print(eeg_raw.info)\n",
    "    print(eeg_raw.info['sfreq'])\n",
    "    print(eeg_raw.info['ch_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
