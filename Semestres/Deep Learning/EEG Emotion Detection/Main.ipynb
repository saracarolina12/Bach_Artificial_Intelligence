{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mne\n",
    "import torch\n",
    "import pickle\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "import import_ipynb\n",
    "from utils import load_eeg_data\n",
    "from utils import load_eye_data\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_session(string):\n",
    "    parts = string.split(\"_\")\n",
    "    return parts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_substring(string, substring):\n",
    "    if substring in string:\n",
    "        index = string.index(substring)\n",
    "        string = string[:index] + string[index+len(substring):]\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_channels(eeg_raw, useless_ch):\n",
    "    ch_names = eeg_raw.ch_names\n",
    "\n",
    "    # drop non-used channels\n",
    "    eeg_raw.drop_channels(useless_ch)\n",
    "    new_ch = eeg_raw.ch_names\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_dict = {0:'Disgust', 1:'Fear', 2:'Sad', 3:'Neutral', 4:'Happy'}\n",
    "def load_eeg_data(eeg_dir, file_name, print_=True):\n",
    "    eeg_data_pickle = np.load( os.path.join(eeg_dir, file_name) )\n",
    "    print(eeg_data_pickle)\n",
    "    data = pickle.loads(eeg_data_pickle['data'])\n",
    "    label = pickle.loads(eeg_data_pickle['label'])\n",
    "    label_dict = {0:'Disgust', 1:'Fear', 2:'Sad', 3:'Neutral', 4:'Happy'}\n",
    "    if(print_ == True):\n",
    "        for i in range(45):\n",
    "            print(f\"\\tSession {i//15+1} - Clip #{i%15+1} ----> {label_dict[label[i][0]]}\")\n",
    "    return data, label"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<numpy.lib.npyio.NpzFile object at 0x0000027DB8CC1AD0>\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    EEG Test Data\n",
    "        data, labels\n",
    "'''\n",
    "\n",
    "#eye_movement_features = './dataset/Eye_movement_features'\n",
    "eeg_features = './dataset/EEG_DE_features'\n",
    "\n",
    "eeg_dir = eeg_features\n",
    "#eye_dir = eye_movement_features\n",
    "test_eeg_file_list = os.listdir(eeg_dir)\n",
    "test_eeg_file_list.sort()\n",
    "\n",
    "res_dir = './res/cv3/'\n",
    "if not os.path.exists(res_dir):\n",
    "    os.makedirs(res_dir)\n",
    "cv = 1\n",
    "\n",
    "# subjectID_sessionID.npz\n",
    "for f_id in test_eeg_file_list:\n",
    "    data, labels = load_eeg_data(eeg_dir, f_id, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _EEG Data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1_1_20180804.cnt\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    EEG Train Data\n",
    "        train_data\n",
    "'''\n",
    "\n",
    "eeg_raw_data = './dataset/EEG_raw'\n",
    "# eye_raw = './dataset/Eye_raw'\n",
    "\n",
    "eeg_dir = eeg_raw_data\n",
    "# eye_dir = eye_raw\n",
    "train_eeg_file_list = os.listdir(eeg_dir)\n",
    "train_eeg_file_list.sort()\n",
    "\n",
    "res_dir = './res/cv3/'\n",
    "if not os.path.exists(res_dir):\n",
    "    os.makedirs(res_dir)\n",
    "\n",
    "\n",
    "useless_ch = ['M1', 'M2', 'VEO', 'HEO']\n",
    "for f_id in train_eeg_file_list: # train_eye_file_list\n",
    "    print(f_id)\n",
    "    eeg_raw = mne.io.read_raw_cnt(f'./dataset/EEG_raw/{f_id}')\n",
    "\n",
    "    drop_channels(eeg_raw, useless_ch)\n",
    "    eeg_raw.plot(start=0, duration=5, scalings='auto', n_channels=62)\n",
    "    image_name = remove_substring(f_id, \".cnt\")\n",
    "    plt.savefig(f'./images/all_channels_data/{image_name}.png', format='png', dpi=300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _Eye Data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Session_1...\n",
      "\t10_1_20180507.xlsx\n",
      "\t11_1_20180510.xlsx\n",
      "\t12_1_20180515.xlsx\n",
      "\t13_1_20180720.xlsx\n",
      "\t14_1_20180420.xlsx\n",
      "\t15_1_20180724.xlsx\n",
      "\t16_1_20180805.xlsx\n",
      "\t1_1_20180804.xlsx\n",
      "\t2_1_20180416.xlsx\n",
      "\t3_1_20180414.xlsx\n",
      "\t4_1_20180414.xlsx\n",
      "\t5_1_20180719.xlsx\n",
      "\t6_1_20180713.xlsx\n",
      "\t7_1_20180401.xlsx\n",
      "\t8_1_20180717.xlsx\n",
      "\t9_1_20180724.xlsx\n",
      "Processing Session_2...\n",
      "\t10_2_20180524.xlsx\n",
      "\t11_2_20180508.xlsx\n",
      "\t12_2_20180508.xlsx\n",
      "\t13_2_20180806.xlsx\n",
      "\t14_2_20180423.xlsx\n",
      "\t15_2_20180807.xlsx\n",
      "\t16_2_20180815.xlsx\n",
      "\t1_2_20180810.xlsx\n",
      "\t2_2_20180419.xlsx\n",
      "\t3_2_20180419.xlsx\n",
      "\t4_2_20180417.xlsx\n",
      "\t5_2_20180728.xlsx\n",
      "\t6_2_20180731.xlsx\n",
      "\t7_2_20180418.xlsx\n",
      "\t8_2_20180802.xlsx\n",
      "\t9_2_20180804.xlsx\n",
      "Processing Session_3...\n",
      "\t10_3_20180626.xlsx\n",
      "\t11_3_20180522.xlsx\n",
      "\t12_3_20180517.xlsx\n",
      "\t13_3_20180725.xlsx\n",
      "\t14_3_20180427.xlsx\n",
      "\t15_3_20180730.xlsx\n",
      "\t16_3_20180813.xlsx\n",
      "\t1_3_20180808.xlsx\n",
      "\t2_3_20180425.xlsx\n",
      "\t3_3_20180424.xlsx\n",
      "\t4_3_20180501.xlsx\n",
      "\t5_3_20180723.xlsx\n",
      "\t6_3_20180802.xlsx\n",
      "\t7_3_20180422.xlsx\n",
      "\t8_3_20180726.xlsx\n",
      "\t9_3_20180728.xlsx\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    EEG Train Data\n",
    "        train_data\n",
    "'''\n",
    "\n",
    "eye_raw = './dataset/Eye_raw'\n",
    "\n",
    "eye_dir = eye_raw\n",
    "train_eye_file_list = os.listdir(eye_dir)\n",
    "train_eye_file_list.sort()\n",
    "\n",
    "res_dir = './res/cv3/'\n",
    "if not os.path.exists(res_dir):\n",
    "    os.makedirs(res_dir)\n",
    "\n",
    "for session_dir in train_eye_file_list:\n",
    "    session_path = os.path.join(eye_dir, session_dir)\n",
    "    print(f\"Processing {session_dir}...\")\n",
    "    for file_name in os.listdir(session_path):\n",
    "        print(\"\\t\"+file_name)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract train EEG data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3378360\n"
     ]
    }
   ],
   "source": [
    "train_data = eeg_raw.get_data()\n",
    "print(len(train_data[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myDataset(Dataset):\n",
    "    def __init__(self, eeg_raw, eye_raw):\n",
    "        self.eeg_data = mne.io.read_raw_cnt(eeg_raw)\n",
    "        self.eye_data = pd.read_excel(eye_raw)\n",
    "\n",
    "    def __len__(self):\n",
    "        return min(len(self.eeg_data), len(self.eye_data))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        eeg_channel_name = 'FP1'  \n",
    "        eeg_signal = self.eeg_data[eeg_channel_name][0][0]\n",
    "\n",
    "        eye_signal = self.eye_data.iloc[index, 0]\n",
    "\n",
    "        eeg_signal_tensor = torch.tensor(eeg_signal)\n",
    "        eye_signal_tensor = torch.tensor(eye_signal)\n",
    "\n",
    "        eeg_mean = torch.mean(eeg_signal_tensor)\n",
    "        eeg_std = torch.std(eeg_signal_tensor)\n",
    "        eye_mean = torch.mean(eye_signal_tensor)\n",
    "        eye_std = torch.std(eye_signal_tensor)\n",
    "\n",
    "        # Normalize the signal data\n",
    "        eeg_signal_tensor = (eeg_signal_tensor - eeg_mean) / eeg_std\n",
    "        eye_signal_tensor = (eye_signal_tensor - eye_mean) / eye_std\n",
    "\n",
    "        return eeg_signal_tensor, eeg_mean, eeg_std, eye_signal_tensor, eye_mean, eye_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./dataset/EEG_raw/1_1_20180804.cnt ./dataset/Eye_raw/Session_1/1_1_20180804.xlsx\n",
      "(tensor([-0.8972, -0.8723, -0.9047,  ...,  3.2437,  3.0493,  2.8220],\n",
      "       dtype=torch.float64), tensor(1.4153e-08, dtype=torch.float64), tensor(5.5059e-05, dtype=torch.float64), tensor(nan, dtype=torch.float64), tensor(432., dtype=torch.float64), tensor(nan, dtype=torch.float64))\n"
     ]
    }
   ],
   "source": [
    "for train_eeg_file in train_eeg_file_list:\n",
    "    session_number = extract_session(train_eeg_file)\n",
    "    train_eye_file = f'./dataset/Eye_raw/Session_{session_number}/{remove_substring(train_eeg_file,\".cnt\")+\".xlsx\"}'\n",
    "    train_eeg_file = f'./dataset/EEG_raw/{train_eeg_file}'\n",
    "    print(train_eeg_file,train_eye_file)\n",
    "\n",
    "    ''' DataLoader '''\n",
    "    # Create a dataset from the EEG and eye files\n",
    "    dataset = myDataset(train_eeg_file, train_eye_file)\n",
    "    # Create a data loader for the dataset\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "    print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "1\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "\n",
    "# Define the train, validation, and test splits (e.g. 70% train, 20% validation, 10% test)\n",
    "train_split = 0.7\n",
    "val_split = 0.2\n",
    "test_split = 0.1\n",
    "\n",
    "# Shuffle the indices of the dataset\n",
    "dataset_size = len(dataset)\n",
    "indices = list(range(dataset_size))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "# Compute the split indices\n",
    "train_split_idx = int(np.floor(train_split * dataset_size))\n",
    "val_split_idx = int(np.floor((train_split + val_split) * dataset_size))\n",
    "\n",
    "# Define the samplers for each subset\n",
    "train_sampler = SubsetRandomSampler(indices[:train_split_idx])\n",
    "val_sampler = SubsetRandomSampler(indices[train_split_idx:val_split_idx])\n",
    "test_sampler = SubsetRandomSampler(indices[val_split_idx:])\n",
    "\n",
    "# Create the data loaders for each subset\n",
    "test_loader = DataLoader(dataset, batch_size=32, sampler=train_sampler)\n",
    "val_loader = DataLoader(dataset, batch_size=32, sampler=val_sampler)\n",
    "train_loader = DataLoader(dataset, batch_size=32, sampler=test_sampler)\n",
    "\n",
    "\n",
    "print(len(test_loader))\n",
    "print(len(val_loader))\n",
    "print(len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, output_dim):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_()\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_()\n",
    "        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[202], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m num_epochs \u001b[39m=\u001b[39m \u001b[39m100\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n\u001b[1;32m----> 9\u001b[0m     \u001b[39mfor\u001b[39;00m i, (inputs, labels) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(test_loader):\n\u001b[0;32m     10\u001b[0m         inputs \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     11\u001b[0m         labels \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[1;32mc:\\Users\\scago\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    632\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    633\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 634\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    635\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    636\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    638\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\scago\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    676\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    677\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 678\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    679\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    680\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\scago\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;49;00m idx \u001b[39min\u001b[39;49;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\scago\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[197], line 11\u001b[0m, in \u001b[0;36mmyDataset.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, index):\n\u001b[0;32m     10\u001b[0m     eeg_channel_name \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mFP1\u001b[39m\u001b[39m'\u001b[39m  \n\u001b[1;32m---> 11\u001b[0m     eeg_signal \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meeg_data[eeg_channel_name][\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\n\u001b[0;32m     13\u001b[0m     eye_signal \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meye_data\u001b[39m.\u001b[39miloc[index, \u001b[39m0\u001b[39m]\n\u001b[0;32m     15\u001b[0m     eeg_signal_tensor \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(eeg_signal)\n",
      "File \u001b[1;32mc:\\Users\\scago\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\mne\\io\\base.py:748\u001b[0m, in \u001b[0;36mBaseRaw.__getitem__\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m    712\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, item):\n\u001b[0;32m    713\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Get raw data and times.\u001b[39;00m\n\u001b[0;32m    714\u001b[0m \n\u001b[0;32m    715\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    746\u001b[0m \n\u001b[0;32m    747\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m  \u001b[39m# noqa: E501\u001b[39;00m\n\u001b[1;32m--> 748\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem(item)\n",
      "File \u001b[1;32mc:\\Users\\scago\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\mne\\io\\base.py:755\u001b[0m, in \u001b[0;36mBaseRaw._getitem\u001b[1;34m(self, item, return_times)\u001b[0m\n\u001b[0;32m    753\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data[sel, start:stop]\n\u001b[0;32m    754\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 755\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_segment(start\u001b[39m=\u001b[39;49mstart, stop\u001b[39m=\u001b[39;49mstop, sel\u001b[39m=\u001b[39;49msel,\n\u001b[0;32m    756\u001b[0m                               projector\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_projector)\n\u001b[0;32m    758\u001b[0m \u001b[39mif\u001b[39;00m return_times:\n\u001b[0;32m    759\u001b[0m     \u001b[39m# Rather than compute the entire thing just compute the subset\u001b[39;00m\n\u001b[0;32m    760\u001b[0m     \u001b[39m# times = self.times[start:stop]\u001b[39;00m\n\u001b[0;32m    761\u001b[0m     \u001b[39m# stop can be None here so don't use it directly\u001b[39;00m\n\u001b[0;32m    762\u001b[0m     times \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marange(start, start \u001b[39m+\u001b[39m data\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], dtype\u001b[39m=\u001b[39m\u001b[39mfloat\u001b[39m)\n",
      "File \u001b[1;32m<decorator-gen-224>:12\u001b[0m, in \u001b[0;36m_read_segment\u001b[1;34m(self, start, stop, sel, data_buffer, projector, verbose)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\scago\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\mne\\io\\base.py:392\u001b[0m, in \u001b[0;36mBaseRaw._read_segment\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    390\u001b[0m     \u001b[39m# reindex back to original file\u001b[39;00m\n\u001b[0;32m    391\u001b[0m     orig_idx \u001b[39m=\u001b[39m _convert_slice(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_read_picks[fi][need_idx])\n\u001b[1;32m--> 392\u001b[0m     _ReadSegmentFileProtector(\u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m_read_segment_file(\n\u001b[0;32m    393\u001b[0m         data[:, this_sl], orig_idx, fi,\n\u001b[0;32m    394\u001b[0m         \u001b[39mint\u001b[39;49m(start_file), \u001b[39mint\u001b[39;49m(stop_file), cals, mult)\n\u001b[0;32m    395\u001b[0m     offset \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m n_read\n\u001b[0;32m    396\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\scago\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\mne\\io\\base.py:2145\u001b[0m, in \u001b[0;36m_ReadSegmentFileProtector._read_segment_file\u001b[1;34m(self, data, idx, fi, start, stop, cals, mult)\u001b[0m\n\u001b[0;32m   2144\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_segment_file\u001b[39m(\u001b[39mself\u001b[39m, data, idx, fi, start, stop, cals, mult):\n\u001b[1;32m-> 2145\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__raw\u001b[39m.\u001b[39;49m\u001b[39m__class__\u001b[39;49m\u001b[39m.\u001b[39;49m_read_segment_file(\n\u001b[0;32m   2146\u001b[0m         \u001b[39mself\u001b[39;49m, data, idx, fi, start, stop, cals, mult)\n",
      "File \u001b[1;32mc:\\Users\\scago\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\mne\\io\\cnt\\cnt.py:448\u001b[0m, in \u001b[0;36mRawCNT._read_segment_file\u001b[1;34m(self, data, idx, fi, start, stop, cals, mult)\u001b[0m\n\u001b[0;32m    446\u001b[0m count \u001b[39m=\u001b[39m n_samps \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m channel_offset \u001b[39m*\u001b[39m chunk_size \u001b[39m+\u001b[39m extra_samps\n\u001b[0;32m    447\u001b[0m n_chunks \u001b[39m=\u001b[39m count \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m chunk_size\n\u001b[1;32m--> 448\u001b[0m samps \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mfromfile(fid, dtype\u001b[39m=\u001b[39;49mdtype, count\u001b[39m=\u001b[39;49mcount)\n\u001b[0;32m    449\u001b[0m samps \u001b[39m=\u001b[39m samps\u001b[39m.\u001b[39mreshape((n_chunks, f_channels, channel_offset),\n\u001b[0;32m    450\u001b[0m                       order\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mC\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    452\u001b[0m \u001b[39m# Intermediate shaping to chunk sizes.\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = LSTM(input_dim=1, hidden_dim=100, num_layers=1, output_dim=1).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (inputs, labels) in enumerate(test_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 10 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, i+1, len(test_loader), loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in valid_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the validation set: {} %'.format(100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the test set: {} %'.format(100 * correct / total))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
