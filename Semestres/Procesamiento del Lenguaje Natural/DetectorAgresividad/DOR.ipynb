{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import matplotlib\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_texts_from_file(path_corpus, path_truth):\n",
    "    tr_txt = []\n",
    "    tr_y = []\n",
    "    with open(path_corpus, \"r\",encoding=\"utf8\") as f_corpus, open(path_truth, \"r\",encoding=\"utf8\") as f_truth:\n",
    "        for tuit in f_corpus:\n",
    "            tr_txt += [tuit]\n",
    "        for label in f_truth:\n",
    "            tr_y += [label] \n",
    "    return tr_txt, tr_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_txt, tr_y = get_texts_from_file(\"./mex_train.txt\", \"./mex_train_labels.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['putos.',\n",
       " 'no',\n",
       " 'tienen',\n",
       " 'madre.',\n",
       " 'ambriados',\n",
       " 'mantenidos.',\n",
       " 'ojetes.',\n",
       " 'como',\n",
       " 'es',\n",
       " 'posible.',\n",
       " 'mejor',\n",
       " 'matarlos']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_txt[5].split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_palabras = []\n",
    "for doc in tr_txt:\n",
    "    corpus_palabras += tokenizer.tokenize(doc) # lista con documentos divididos por espacios (contando signos de puntuaci칩n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "tokenizer = TweetTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['putos',\n",
       " '.',\n",
       " 'no',\n",
       " 'tienen',\n",
       " 'madre',\n",
       " '.',\n",
       " 'ambriados',\n",
       " 'mantenidos',\n",
       " '.',\n",
       " 'ojetes',\n",
       " '.',\n",
       " 'como',\n",
       " 'es',\n",
       " 'posible',\n",
       " '.',\n",
       " 'mejor',\n",
       " 'matarlos']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(tr_txt[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_palabras = []\n",
    "for doc in tr_txt:\n",
    "    corpus_palabras += tokenizer.tokenize(doc) # lista con documentos divididos por espacios (contando signos de puntuaci칩n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist = nltk.FreqDist(corpus_palabras) # cu치ntas veces aparece cada palabra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortFreqDict(freqdict):\n",
    "    aux = [(freqdict[key], key) for key in freqdict] #lista de pares ordenada (m치s frecuente a menos)\n",
    "    aux.sort()\n",
    "    aux.reverse()\n",
    "    return aux #regresa el objeto ordenado en reversa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3383, 'que'),\n",
       " (3357, 'de'),\n",
       " (2774, '.'),\n",
       " (2629, 'a'),\n",
       " (2433, 'la'),\n",
       " (2266, 'y'),\n",
       " (1824, 'no'),\n",
       " (1613, 'me'),\n",
       " (1505, '!'),\n",
       " (1303, 'el')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V = sortFreqDict(fdist)\n",
    "V = V[:5000]\n",
    "V[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    }
   ],
   "source": [
    "dict_indices = dict()\n",
    "cont = 0\n",
    "for weight, word in V:\n",
    "    dict_indices[word]=cont\n",
    "    cont+=1\n",
    "print(len(dict_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_txt, val_y = get_texts_from_file(\"./mex_val.txt\", \"./mex_val_labels.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DOR(tweets, V, dict_indices):\n",
    "    DOR = np.zeros((len(tweets),len(V)), dtype=float)\n",
    "    for i, tweet in enumerate(tweets):\n",
    "        word_map = nltk.FreqDist(tokenizer.tokenize(tweet))\n",
    "        for word in word_map:\n",
    "            if word in dict_indices:\n",
    "                dftj = 1 + np.log(word_map[word])\n",
    "                DOR[i, dict_indices[word]] = dftj * np.log(len(V)/len(tweet))\n",
    "    return DOR.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5544 5000 5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3.99540461, 3.82584531, 6.38699318, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [6.76480806, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        4.54690128],\n",
       "       [0.        , 0.        , 0.        , ..., 4.43965575, 0.        ,\n",
       "        4.54690128],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(tr_txt), len(V), len(dict_indices))\n",
    "\n",
    "DOR_tr = DOR(tr_txt, V, dict_indices)\n",
    "DOR_tr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
